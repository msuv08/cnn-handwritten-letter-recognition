{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21f69704",
   "metadata": {},
   "source": [
    "# CS 342 Final Project - Letter Recognition CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1664c6b",
   "metadata": {},
   "source": [
    "Mrityunjay Mishra (eid: mm94424), Mihir Suvarna (eid: mms5776), Daniel Sialm (eid: dhs833)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55a6548",
   "metadata": {},
   "source": [
    "## Project Description\n",
    "\n",
    "This project aims to create a convolutional neural network (CNN) for the task of letter recognition. The task of letter recognition, or more generally speaking, text recognition (also known as optical character recognition, or OCR) has gained much importance in recent years due to emerging applications. For example, OCR software can be used to convert handwritten text into digital text and robots use cameras to read signs in their environment. Letter recognition is a subtask of text recognition with wide applications as well - iPhones use letter recognition to convert handwritten characters to text. Due to the increasing importance of these tasks, we aim to create a robust CNN that is able to correctly classify handwritten and digital letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75da0fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run these two blocks to load important libraries and set things up\n",
    "from letter_recognition_functions import *\n",
    "from ttf_to_png import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1977be9",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7c98fb",
   "metadata": {},
   "source": [
    "We collected handwritten letters from 23 students, each of whom wrote the alphabet 10 times. This gave us about 6K data points to train and test our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3894a12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'N/A': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n"
     ]
    }
   ],
   "source": [
    "letter_to_label = dict()\n",
    "classes = ['N/A', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "for i in range(len(classes)):\n",
    "    letter_to_label[classes[i]] = i\n",
    "print(letter_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "600d7ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed P18-Regular.ttf\n",
      "Processed P0-Regular.ttf\n",
      "Processed P11-Regular.ttf\n",
      "Processed P9-Regular.ttf\n",
      "Processed P23-Regular.ttf\n",
      "Processed P14-Regular.ttf\n",
      "Processed P5-Regular.ttf\n",
      "Processed P6-Regular.ttf\n",
      "Processed P17-Regular.ttf\n",
      "Processed P20-Regular.ttf\n",
      "Processed P12-Regular.ttf\n",
      "Processed P3-Regular.ttf\n",
      "Processed P4-Regular.ttf\n",
      "Processed P15-Regular.ttf\n",
      "Processed P22-Regular.ttf\n",
      "Processed P10-Regular.ttf\n",
      "Processed P8-Regular.ttf\n",
      "Processed P19-Regular.ttf\n",
      "Processed P1-Regular.ttf\n",
      "Processed P2-Regular.ttf\n",
      "Processed P13-Regular.ttf\n",
      "Processed P21-Regular.ttf\n",
      "Processed P16-Regular.ttf\n",
      "Processed P7-Regular.ttf\n"
     ]
    }
   ],
   "source": [
    "src_dir = 'data/collected_ttfs'\n",
    "dst_dir = 'data/collected_letters_pngs'\n",
    "num_ttfs = convert_ttf(src_dir, dst_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06d182b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = 'data/collected_letters_pngs'\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "num_train = int(0.7 * num_ttfs)\n",
    "num_val = (num_ttfs - num_train) // 2\n",
    "\n",
    "imgs_train = []\n",
    "imgs_val = []\n",
    "imgs_test = []\n",
    "labels_train = []\n",
    "labels_val = []\n",
    "labels_test = []\n",
    "for f in glob.glob(os.path.join(src_dir, '*.png')):\n",
    "    ftitle, fext = os.path.splitext(os.path.basename(f))\n",
    "    letter = ftitle.split(\"_\")[1]\n",
    "    # gets which person wrote this font\n",
    "    p_val = int(ftitle.split(\"_\")[0].split(\"-\")[0][1:])\n",
    "    im = Image.open(f).convert('L')\n",
    "    \n",
    "    if p_val <= num_train:\n",
    "        imgs_train += transform(im).detach().tolist()\n",
    "        labels_train.append(letter_to_label[letter])\n",
    "    elif p_val <= num_train + num_val:\n",
    "        imgs_val += transform(im).detach().tolist()\n",
    "        labels_val.append(letter_to_label[letter])\n",
    "    else:\n",
    "        imgs_test += transform(im).detach().tolist()\n",
    "        labels_test.append(letter_to_label[letter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1a4ba3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_collected = create_loader(imgs_train, labels_train)\n",
    "val_loader_collected = create_loader(imgs_val, labels_val)\n",
    "test_loader_collected = create_loader(imgs_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "feffc6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization for our collected dataset\n",
    "img, label = get_input(train_loader_collected)\n",
    "plt.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "print(\"Label: %s\" % classes[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2599f8d",
   "metadata": {},
   "source": [
    "## Defining a basic LetterCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ed8e2c",
   "metadata": {},
   "source": [
    "We define a basic CNN with 1 convolutional layer, 1 MaxPool layer, a ReLU activation and finally a fully connected layer for our model. This model will be used throughout our prelimenary expriments (i.e. before our computational experiments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "52067f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class letterCNN(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super().__init__()\n",
    "        self.classes = classes\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(5,5), stride=1),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1152, len(self.classes))\n",
    "        )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        output = self.layers(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58a7299",
   "metadata": {},
   "source": [
    "## Testing the basic LetterCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ca49e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c64328f4ed4a29ae9b16a01058b570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      " Train loss: 3.25055\n",
      "   Val loss: 3.13403\n",
      "\n",
      "EPOCH 1\n",
      " Train loss: 2.98430\n",
      "   Val loss: 2.89094\n",
      "\n",
      "EPOCH 2\n",
      " Train loss: 2.61690\n",
      "   Val loss: 2.63182\n",
      "\n",
      "EPOCH 3\n",
      " Train loss: 2.22144\n",
      "   Val loss: 2.35645\n",
      "\n",
      "EPOCH 4\n",
      " Train loss: 1.90629\n",
      "   Val loss: 2.13534\n",
      "\n",
      "EPOCH 5\n",
      " Train loss: 1.66781\n",
      "   Val loss: 2.13455\n",
      "\n",
      "EPOCH 6\n",
      " Train loss: 1.50729\n",
      "   Val loss: 2.06651\n",
      "\n",
      "EPOCH 7\n",
      " Train loss: 1.39178\n",
      "   Val loss: 2.00800\n",
      "\n",
      "EPOCH 8\n",
      " Train loss: 1.29860\n",
      "   Val loss: 2.07046\n",
      "\n",
      "EPOCH 9\n",
      " Train loss: 1.22753\n",
      "   Val loss: 1.96096\n",
      "\n"
     ]
    }
   ],
   "source": [
    "basic_model_collected = letterCNN(classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(basic_model_collected.parameters(), lr=1e-3)\n",
    "train_network(basic_model_collected, train_loader_collected, val_loader_collected, criterion, optimizer, nepoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "efb36f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 46.154\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc, true, pred = test_network(basic_model_collected, test_loader_collected)\n",
    "print('Test accuracy: %0.3f' % acc)\n",
    "\n",
    "display_contingency_matrix(len(basic_model_collected.classes), pred, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd60841e",
   "metadata": {},
   "source": [
    "We see quite a bit of overfitting (since the validation loss is not converging and, in fact, even increasing). This naturally causes our accuracy to be quite low. While this accuracy is still quite good - $48.718 / (1 / 26) = 12.67$ times increase in accuracy from just taking a random guess - we can still do better. The reason for this poor performance is because only a few people's data was obtained. This causes our model to be biased towards the the handwriting of a few people and prevents it from generalizing well. Thus, we will combine our dataset with the EMNIST dataset to create a better model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d0599f",
   "metadata": {},
   "source": [
    "## EMNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "65c076b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset EMNIST\n",
      "    Number of datapoints: 124800\n",
      "    Root location: EMNIST\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "Dataset EMNIST\n",
      "    Number of datapoints: 20800\n",
      "    Root location: EMNIST\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "# Download the EMNIST dataset and load it as tensors\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "save_dir = 'EMNIST'\n",
    "\n",
    "transform = transforms.ToTensor() # Convert the image into a torch tensor.\n",
    "\n",
    "train_set = datasets.EMNIST(save_dir, split=\"letters\", download=True, train=True, transform=transform)\n",
    "test_set = datasets.EMNIST(save_dir, split=\"letters\", download=True, train=False, transform=transform)\n",
    "\n",
    "print(train_set)\n",
    "print(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1cc0f048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create samplers for the training and validation sets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "ncollected = len(train_loader_collected + val_loader_collected) * train_loader.collected.batch_size\n",
    "\n",
    "ntotal = 60000\n",
    "ntrain = int(0.70*ntotal)\n",
    "nval = ntotal - ntrain\n",
    "\n",
    "val_ix = np.random.choice(range(ntotal), size=nval, replace=False)\n",
    "train_ix = list(set(range(ntotal)) - set(val_ix))\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_ix)\n",
    "val_sampler = SubsetRandomSampler(val_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c1c36234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the data sets\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, sampler=train_sampler)\n",
    "val_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, sampler=val_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "96903a3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'collected'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/k7/zz5h09l90lz91rrnxkcsyfv00000gn/T/ipykernel_99802/863942695.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mncollected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader_collected\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader_collected\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'collected'"
     ]
    }
   ],
   "source": [
    "ncollected = len(train_loader_collected) + len(val_loader_collected) * train_loader.collected.batch_size\n",
    "print(len(train_loader) * 64)\n",
    "print(len(val_loader) * 64)\n",
    "print(len(test_loader) * 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bc5266dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: m\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization EMNIST\n",
    "img, label = get_input(train_loader)\n",
    "# print label\n",
    "index = 0\n",
    "plt.imshow(img.reshape((28, 28)).T, cmap='Greys_r')\n",
    "print(\"Label: %s\" % classes[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07941a2b",
   "metadata": {},
   "source": [
    "## Combining EMNIST with our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aacd79b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train_loader = combine_loaders(train_loader, train_loader_collected, fromEMNIST=True)\n",
    "combined_val_loader = combine_loaders(val_loader, val_loader_collected, fromEMNIST=True)\n",
    "combined_test_loader = combine_loaders(test_loader, test_loader_collected, fromEMNIST=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "09211f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: k\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Verifying combined\n",
    "img, label = get_input(combined_test_loader)\n",
    "# print label\n",
    "index = 0\n",
    "plt.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "print(\"Label: %s\" % classes[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb1e5d0",
   "metadata": {},
   "source": [
    "## Making a new LetterCNN on the Combined Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ab2a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_model = letterCNN(classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(basic_model.parameters(), lr=1e-3)\n",
    "train_network(basic_model, combined_train_loader, combined_val_loader, criterion, optimizer, nepoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494689c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, true, pred = test_network(basic_model, combined_test_loader)\n",
    "print('Test accuracy: %0.3f' % acc)\n",
    "\n",
    "display_contingency_matrix(len(basic_model.classes), pred, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d33042",
   "metadata": {},
   "source": [
    "We see immediate improvement in our results. The new model does not overfit (since the validation loss decreases) and generalizes quite well, giving us an accuracy of about 86%, an increase of about 79% in accuracy compared to our older model. This shows that our model works well if a good dataset is provided. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba4a9d0",
   "metadata": {},
   "source": [
    "## Computational Experiment 1 - Regularization\n",
    "\n",
    "Our first set of computational experiments will deal with better regularization of our model in hopes of creating a more generalized model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e55838",
   "metadata": {},
   "source": [
    "### 1a) Regularization through data augmentation - add digital fonts\n",
    "\n",
    "For this experiment, we add digital fonts to our dataset. Specifically, we take about 100 different fonts and add their characters to our dataset. We hypothesize that this will increase the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fc6dbb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Georgia.ttf\n",
      "Processed Bodoni 72 Smallcaps Book.ttf\n",
      "Processed Silom.ttf\n",
      "Processed Bradley Hand Bold.ttf\n",
      "Ignored .DS_Store\n",
      "Processed AppleGothic.ttf\n",
      "Processed Trebuchet MS.ttf\n",
      "Processed Academy Engraved LET Fonts.ttf\n",
      "Processed Trattatello.ttf\n",
      "Processed BigCaslon.ttf\n",
      "Processed Lao Sangam MN.ttf\n",
      "Processed Luminari.ttf\n",
      "Processed Times New Roman.ttf\n",
      "Processed Brush Script.ttf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 extra bytes in post.stringData array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Chalkduster.ttf\n",
      "Processed Apple Chancery.ttf\n",
      "Processed AppleMyungjo.ttf\n",
      "Processed NotoSansCarian-Regular.ttf\n",
      "Processed Courier New.ttf\n",
      "Processed Skia.ttf\n",
      "Processed Impact.ttf\n",
      "Processed NotoSansElbasan-Regular.ttf\n",
      "Processed PartyLET-plain.ttf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 extra bytes in post.stringData array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Arial.ttf\n",
      "Processed Ayuthaya.ttf\n",
      "Processed Khmer Sangam MN.ttf\n",
      "Processed Comic Sans MS.ttf\n",
      "Processed DIN Alternate Bold.ttf\n",
      "Processed Sathu.ttf\n",
      "Processed Tahoma.ttf\n",
      "Processed PlantagenetCherokee.ttf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 extra bytes in post.stringData array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Microsoft Sans Serif.ttf\n",
      "Processed Krungthep.ttf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 extra bytes in post.stringData array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Andale Mono.ttf\n",
      "Processed Herculanum.ttf\n",
      "Processed Verdana.ttf\n"
     ]
    }
   ],
   "source": [
    "src_dir = 'data/digital_ttfs'\n",
    "dst_dir = 'data/digital_letters_pngs'\n",
    "num_ttfs = convert_ttf(src_dir, dst_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "27d56d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = \"data/digital_letters_pngs\"\n",
    "\n",
    "num_train = int(0.7 * num_ttfs)\n",
    "num_val = (num_ttfs - num_train) // 2\n",
    "\n",
    "imgs_train = []\n",
    "imgs_val = []\n",
    "imgs_test = []\n",
    "labels_train = []\n",
    "labels_val = []\n",
    "labels_test = []\n",
    "idx = 0\n",
    "for f in glob.glob(os.path.join(src_dir, '*.png')):\n",
    "    ftitle, fext = os.path.splitext(os.path.basename(f))\n",
    "    letter = ftitle.split(\"_\")[1].lower()\n",
    "    im = Image.open(f).convert('L')\n",
    "\n",
    "    if idx < num_train:\n",
    "        imgs_train += transform(im).detach().tolist()\n",
    "        labels_train.append(letter_to_label[letter])\n",
    "    elif idx < num_train + num_val:\n",
    "        imgs_val += transform(im).detach().tolist()\n",
    "        labels_val.append(letter_to_label[letter])\n",
    "    else:\n",
    "        imgs_test += transform(im).detach().tolist()\n",
    "        labels_test.append(letter_to_label[letter])\n",
    "    \n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "467c0169",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_digital = create_loader(imgs_train, labels_train)\n",
    "val_loader_digital = create_loader(imgs_val, labels_val)\n",
    "test_loader_digital = create_loader(imgs_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9802ee26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: g\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization of a digital font\n",
    "img, label = get_input(train_loader_digital)\n",
    "plt.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "print(\"Label: %s\" % classes[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a2b8e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine digital with other data\n",
    "combined_train_digital_loader = combine_loaders(combined_train_loader, train_loader_digital)\n",
    "combined_val_digital_loader = combine_loaders(combined_val_loader, val_loader_digital)\n",
    "combined_test_digital_loader = combine_loaders(combined_test_loader, test_loader_digital)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a8f979c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: k\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Verifiying combined\n",
    "img, label = get_input(combined_test_digital_loader)\n",
    "plt.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "print(\"Label: %s\" % classes[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d087317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with augmented data\n",
    "model_digital = letterCNN(classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_digital.parameters(), lr=1e-3)\n",
    "train_network(model_digital, combined_train_digital_loader, combined_val_digital_loader, criterion, optimizer, nepoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdf412e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc, true, pred = test_network(model_digital, combined_test_digital_loader)\n",
    "print('Test accuracy: %0.3f' % acc)\n",
    "\n",
    "display_contingency_matrix(len(model_digital.classes), pred, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d9322a",
   "metadata": {},
   "source": [
    "The accuracy of the model with the augmented data did not improve (in fact, it decreased by about 0.4%). It is possible that this happened because we only included 100 fonts - we believe that including more fonts in our dataset should improve the accuracy of our model. However, given current results, it is reasonable to say that the improvement in accuracy will not be very significant even if more fonts are added. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811559a7",
   "metadata": {},
   "source": [
    "### 1b) Regularization through dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ccb4d5",
   "metadata": {},
   "source": [
    "We hypothesize that adding dropout will decrease the accuracy of our model because each image is simply a 28 x 28 image of a letter, and dropping out even the smallest learned feature for a small image should impact the accuracy negatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8042ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class letterCNNDropout(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super().__init__()\n",
    "        self.classes = classes\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(5,5), stride=1),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(1152, len(self.classes))\n",
    "        )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        output = self.layers(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c09b34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dropout = letterCNNDropout(classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_dropout.parameters(), lr=1e-3)\n",
    "train_network(model_dropout, combined_train_loader, combined_val_loader, criterion, optimizer, nepoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b150871b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc, true, pred = test_network(model_dropout, combined_test_loader)\n",
    "print('Test accuracy: %0.3f' % acc)\n",
    "\n",
    "display_contingency_matrix(len(model_dropout.classes), pred, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29d15bf",
   "metadata": {},
   "source": [
    "As hypothesized, the accuracy of our model did drop using dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122f4bbd",
   "metadata": {},
   "source": [
    "### 1c) Regularization through Average Pooling\n",
    "\n",
    "We hypothesize that the accuracy of our model will stay about the same with average pooling. We believe this to be the case because we have a network with just one convolutional layer which learns on fairly small images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0017b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the combined dataset \n",
    "img, label = get_input(combined_train_loader)\n",
    "plt.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "print(\"Label: %s\" % classes[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbf4483",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize kernels with max pooling\n",
    "conv_out = basic_model.layers[0](img)\n",
    "_ = display_pool_outputs(basic_model.layers[1], conv_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80da4c7",
   "metadata": {},
   "source": [
    "We see that the kernels are a little blotchy. This is to be expected as a result of max pooling. The learned kernels with average pooling should be a little smoother. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81c814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class letterCNNAvgPool(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super().__init__()\n",
    "        self.classes = classes\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(5,5), stride=1),\n",
    "            nn.AvgPool2d(kernel_size=(2,2), stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1152, len(self.classes))\n",
    "        )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        output = self.layers(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5169ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_avgpool = letterCNNAvgPool(classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_avgpool.parameters(), lr=1e-3)\n",
    "train_network(model_avgpool, combined_train_loader, combined_val_loader, criterion, optimizer, nepoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e670b4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, true, pred = test_network(model_avgpool, combined_test_loader)\n",
    "print('Test accuracy: %0.3f' % acc)\n",
    "\n",
    "display_contingency_matrix(len(model_avgpool.classes), pred, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bd8121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize average pooling\n",
    "conv_out = model_avgpool.layers[0](img)\n",
    "_ = display_pool_outputs(model_avgpool.layers[1], conv_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089dd56d",
   "metadata": {},
   "source": [
    "The learned kernels for average pooling are smoother than the learned kernels for max pooling, as expected. As hypothesized, the accuracy of our model did not improve with average pooling. However, it is interesting that the accuracy decreased a bit with average pooling. This suggests that, for the task of letter recognition, max pooling is a better strategy than average pooling. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0829dc6e",
   "metadata": {},
   "source": [
    "### 1d) Regularization through Early Stopping\n",
    "\n",
    "As our final experiment for the first computational experiment, we implement early stopping. We hypothesize that early stopping should improve the accuracy marginally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d590e600",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_early_stopping = letterCNN(classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_early_stopping.parameters(), lr=1e-3)\n",
    "train_network(model_early_stopping, combined_train_loader, combined_val_loader, criterion, optimizer, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8cf3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, true, pred = test_network(model_early_stopping, combined_test_loader)\n",
    "print('Test accuracy: %0.3f' % acc)\n",
    "\n",
    "display_contingency_matrix(len(model_early_stopping.classes), pred, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b844d592",
   "metadata": {},
   "source": [
    "The accuracy of our model with early stopping did not improve and stayed about the same. \n",
    "\n",
    "All these computational experiments show that, as defined, our `letterCNN` is actually well defined and supports a good amount of generalization. To get good results, then, we must pick the dataset carefully so that our model generalizes to a variety of handwriting and font styles. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c74c3f",
   "metadata": {},
   "source": [
    "## Computational Experiment 2 - Architecture\n",
    "\n",
    "As our second computational experiment, we will visualize the learned kernels of our basic model and then change the architecture to create a new model in hopes of creating a more accurate network. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e747cf9",
   "metadata": {},
   "source": [
    "### Visualizing previous kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3c3303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the weights from the learned model\n",
    "conv1wt = basic_model.layers[0].weight.data.numpy()\n",
    "display_kernels(conv1wt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d073003",
   "metadata": {},
   "source": [
    "It seems that in our basic model, the kernels are learning to identify specific edge types within letters. For example, in Kernel 3, it seems that the model is learning to identify horizontal edges while in Kernel 6 the model is learning to identify vertical edges. Based upon this, we hypothesize that adding a second convolutional layer to our current model will help it learn the features/characterisitics of each letter better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10205d8",
   "metadata": {},
   "source": [
    "### 2a) Double Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4dc8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class letterCNNDouble(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super().__init__()\n",
    "        self.classes = classes\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(5,5), stride=1),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=8, out_channels=64, kernel_size=(5,5), stride=1),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024, len(self.classes))\n",
    "        )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dde111",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_double_layer = letterCNNDouble(classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_double_layer.parameters(), lr=1e-3)\n",
    "train_network(model_double_layer, combined_train_loader, combined_val_loader, criterion, optimizer, nepoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe90fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, true, pred = test_network(model_double_layer, combined_test_loader)\n",
    "print('Test accuracy: %0.3f' % acc)\n",
    "\n",
    "display_contingency_matrix(len(model_double_layer.classes), pred, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5390be53",
   "metadata": {},
   "source": [
    "As we can see, adding a seecond layer did indeed increase the accuracy by about 4% as per our hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62445bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the weights from the learned model\n",
    "conv2wtsfirst = model_double_layer.layers[0].weight.data.numpy()\n",
    "display_kernels(conv2wtsfirst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ecfddb",
   "metadata": {},
   "source": [
    "The first layer is still learning the hard edges of each letter as the single convolutional layer network (i.e. our basic model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fae13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the weights from the learned model\n",
    "conv2wtssecond = model_double_layer.layers[3].weight.data.numpy()\n",
    "display_kernels(conv2wtssecond)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfed915",
   "metadata": {},
   "source": [
    "The second layer seems to be learning more precise/specific features. Note that we only display the first channel of each of the 64 channels in the second convolution layer in `letterCNNDouble`. Still, it is quite obvious that the second layer's kernels are learning more precise features. It seems that the second layer is starting to learn more nuances between the edges of each letter - however, that is much harder to confirm. Still, as hypothesized, adding a second convolution layer to our basic CNN helped the new model learn more precise features about each letter and this in turn increased the accuracy of our new model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a4aa03",
   "metadata": {},
   "source": [
    "### 2b) Changing the Kernel Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53490e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class letterCNNKernel(nn.Module):\n",
    "    def __init__(self, classes, size):\n",
    "        super().__init__()\n",
    "        self.classes = classes\n",
    "        output_size = (((28 - size) + 1) // 2) ** 2 * 8 \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(size,size), stride=1),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(output_size, len(self.classes))\n",
    "        )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7195d240",
   "metadata": {},
   "source": [
    "#### Size 3 kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5549b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kernel_3 = letterCNNKernel(classes, 3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_kernel_3.parameters(), lr=1e-3)\n",
    "train_network(model_kernel_3, combined_train_loader, combined_val_loader, criterion, optimizer, nepoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099d1d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, true, pred = test_network(model_kernel_3, combined_test_loader)\n",
    "print('Test accuracy: %0.3f' % acc)\n",
    "\n",
    "display_contingency_matrix(len(model_kernel_3.classes), pred, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d99471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the weights from the learned model\n",
    "convk3wts = model_kernel_3.layers[0].weight.data.numpy()\n",
    "display_kernels(convk3wts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dde41aa",
   "metadata": {},
   "source": [
    "#### Size 8 kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d9d5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kernel_8 = letterCNNKernel(classes, 8)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_kernel_8.parameters(), lr=1e-3)\n",
    "train_network(model_kernel_8, combined_train_loader, combined_val_loader, criterion, optimizer, nepoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f21c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, true, pred = test_network(model_kernel_8, combined_test_loader)\n",
    "print('Test accuracy: %0.3f' % acc)\n",
    "\n",
    "display_contingency_matrix(len(model_kernel_8.classes), pred, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5cb5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the weights from the learned model\n",
    "convk8wts = model_kernel_8.layers[0].weight.data.numpy()\n",
    "display_kernels(convk8wts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1ffce9",
   "metadata": {},
   "source": [
    "#### Size 11 kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d6a896",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kernel_11 = letterCNNKernel(classes, 11)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_kernel_11.parameters(), lr=1e-3)\n",
    "train_network(model_kernel_11, combined_train_loader, combined_val_loader, criterion, optimizer, nepoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e573a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, true, pred = test_network(model_kernel_11, combined_test_loader)\n",
    "print('Test accuracy: %0.3f' % acc)\n",
    "\n",
    "display_contingency_matrix(len(model_kernel_11.classes), pred, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd202051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the weights from the learned model\n",
    "convk11wts = model_kernel_11.layers[0].weight.data.numpy()\n",
    "display_kernels(convk11wts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b858659f",
   "metadata": {},
   "source": [
    "## Optimized Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b14cf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_inputs_kernel_3 = get_optimized_inputs(model_kernel_3, nepochs=1000)\n",
    "optimized_inputs_kernel_5 = get_optimized_inputs(basic_model, nepochs=1000)\n",
    "optimized_inputs_kernel_8 = get_optimized_inputs(model_kernel_8, nepochs=1000)\n",
    "optimized_inputs_kernel_11 = get_optimized_inputs(model_kernel_11, nepochs=1000)\n",
    "optimized_inputs_double_conv = get_optimized_inputs(model_double_layer, nepochs=1000, validate_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabe2139",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_optimized_inputs(optimized_inputs_kernel_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4611ddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_optimized_inputs(optimized_inputs_kernel_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adeccc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_optimized_inputs(optimized_inputs_kernel_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff18ad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_optimized_inputs(optimized_inputs_kernel_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada2f9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_optimized_inputs(optimized_inputs_double_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1994a9e1",
   "metadata": {},
   "source": [
    "## Additional Visualizations\n",
    "\n",
    "We provide some additional visualizations here for reference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274b1a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing a different letter from the combined dataset\n",
    "img, label = get_input(combined_train_loader)\n",
    "plt.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "print(\"Label: %s\" % classes[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6556dc",
   "metadata": {},
   "source": [
    "#### Single Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6861d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the learned kernels for the sinlge convolutional layer network\n",
    "conv1_layer = basic_model.layers[0]\n",
    "display_kernels(conv1_layer.weight.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec306d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing convolved outputs for the sinlge convolutional layer network\n",
    "conv_outs = display_conv_outputs(conv1_layer, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4a1919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the max pooling layer outputs for the sinlge convolutional layer network\n",
    "_ = display_pool_outputs(basic_model.layers[1], conv_outs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be448a9",
   "metadata": {},
   "source": [
    "#### Double Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adb31fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the learned kernels of the first convolution layer of the double covolutional network\n",
    "conv2_layer1 = model_double_layer.layers[0]\n",
    "display_kernels(conv2_layer1.weight.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b10df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the convolved outputs of first convolution layer of the double covolutional network\n",
    "outs_layer1 = display_conv_outputs(model_double_layer.layers[0], img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d65f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the max pool outputs of the first max pool layer of the double covolutional network\n",
    "pooled_layer1 = display_pool_outputs(model_double_layer.layers[1], outs_layer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f688a109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the learned kernels of the second convolution layer of the double covolutional network\n",
    "conv2_layer2 = model_double_layer.layers[3]\n",
    "display_kernels(conv2_layer2.weight.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0599d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the convolved outputs of the second convolution layer of the double covolutional network\n",
    "inputs_layer2 = model_double_layer.layers[2](pooled_layer1)\n",
    "outs_layer2 = display_conv_outputs(model_double_layer.layers[3], inputs_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d468625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the max pool outputs of second max pool layer of the double covolutional network\n",
    "_ = display_pool_outputs(model_double_layer.layers[4], outs_layer2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
